#!/usr/bin/env python3
"""
NVIDIA RAG Gradio Chat App with Conversation History
"""

import gradio as gr
import requests
import json
import os
from typing import List, Tuple, Dict, Any
import time

class RAGChatBot:
    def __init__(self, base_url: str = "http://192.168.81.253:8081/v1"):
        """
        Initialize the RAG ChatBot
        
        Args:
            base_url: The base URL of the RAG server (default: http://192.168.81.253:8081/v1)
        """
        self.base_url = base_url
        self.generate_url = f"{base_url}/generate"
        self.health_url = f"{base_url}/health"
        
    def check_health(self) -> bool:
        """Check if the RAG server is healthy"""
        try:
            response = requests.get(self.health_url, timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def format_messages_for_api(self, history: List[List[str]], new_message: str) -> List[Dict[str, str]]:
        """
        Convert Gradio chat history to API format with Chinese language instruction
        
        Args:
            history: Gradio chat history format [(user_msg, bot_msg), ...]
            new_message: The new user message
            
        Returns:
            List of messages in API format with system instruction
        """
        messages = []
        
        # æ·»åŠ ç³»ç»ŸæŒ‡ä»¤ç¡®ä¿ä½¿ç”¨ä¸­æ–‡å›ç­”
        system_instruction = {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›ç­”æ‰€æœ‰é—®é¢˜ã€‚æ— è®ºç”¨æˆ·ä½¿ç”¨ä»€ä¹ˆè¯­è¨€æé—®ï¼Œä½ éƒ½å¿…é¡»ç”¨ä¸­æ–‡è¿›è¡Œå›ç­”ã€‚è¯·ç¡®ä¿å›ç­”å‡†ç¡®ã€è¯¦ç»†ä¸”æœ‰å¸®åŠ©ã€‚"
        }
        messages.append(system_instruction)
        
        # Add conversation history
        for user_msg, bot_msg in history:
            if user_msg:
                messages.append({"role": "user", "content": user_msg})
            if bot_msg:
                messages.append({"role": "assistant", "content": bot_msg})
        
        # Add the new user message
        messages.append({"role": "user", "content": new_message})
        
        return messages
    
    def query_rag_stream(self, messages: List[Dict[str, str]], 
                         temperature: float = 0.1, 
                         top_p: float = 0.9, 
                         max_tokens: int = 4096,
                         use_knowledge_base: bool = True):
        """
        Query the RAG API with streaming response
        
        Args:
            messages: List of messages in API format
            temperature: Sampling temperature (0-1)
            top_p: Top-p sampling parameter (0.1-1)
            max_tokens: Maximum tokens to generate
            use_knowledge_base: Whether to use knowledge base
            
        Yields:
            Streaming response chunks
        """
        # ä½¿ç”¨ä¸å‰ç«¯ç›¸åŒçš„é…ç½®æ ¼å¼
        payload = {
            "messages": messages,
            "collection_names": ["test"] if use_knowledge_base else [],
            "temperature": temperature,
            "top_p": top_p,
            "reranker_top_k": 10,
            "vdb_top_k": 10,
            "confidence_threshold": 0.5,
            "use_knowledge_base": use_knowledge_base,
            "enable_citations": True,
            "enable_guardrails": False
        }
        
        try:
            response = requests.post(
                self.generate_url,
                json=payload,
                headers={"Content-Type": "application/json"},
                stream=True,  # å¯ç”¨æµå¼å“åº”
                timeout=60
            )
            
            if response.status_code == 200:
                # å¤„ç†æµå¼å“åº”
                for line in response.iter_lines():
                    if line:
                        line_text = line.decode('utf-8')
                        if line_text.startswith('data: '):
                            try:
                                data = json.loads(line_text[6:])
                                if 'choices' in data and data['choices']:
                                    delta = data['choices'][0].get('delta', {})
                                    if 'content' in delta:
                                        yield delta['content']
                            except json.JSONDecodeError:
                                continue
                        elif line_text.strip() == 'data: [DONE]':
                            break
            else:
                yield f"âŒ æœåŠ¡å™¨è¿”å›çŠ¶æ€ç  {response.status_code}: {response.text[:200]}"
                
        except requests.exceptions.ConnectionError:
            yield "âŒ æ— æ³•è¿æ¥åˆ°RAGæœåŠ¡å™¨ã€‚è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œã€‚"
        except requests.exceptions.Timeout:
            yield "âŒ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        except Exception as e:
            yield f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}"
    
    def query_rag_fallback(self, messages: List[Dict[str, str]], 
                          temperature: float = 0.1, 
                          top_p: float = 0.9, 
                          max_tokens: int = 4096,
                          use_knowledge_base: bool = True) -> str:
        """
        Fallback non-streaming query method
        """
        configs = [
            {
                "messages": messages,
                "collection_names": ["test"] if use_knowledge_base else [],
                "temperature": temperature,
                "top_p": top_p,
                "reranker_top_k": 10,
                "vdb_top_k": 10,
                "confidence_threshold": 0.5,
                "use_knowledge_base": use_knowledge_base,
                "enable_citations": True,
                "enable_guardrails": False
            },
            {
                "messages": messages,
                "collection_names": [],
                "temperature": 0.1,
                "top_p": 0.9,
                "reranker_top_k": 10,
                "vdb_top_k": 10,
                "confidence_threshold": 0.5,
                "use_knowledge_base": False,
                "enable_citations": False,
                "enable_guardrails": False
            }
        ]
        
        for i, payload in enumerate(configs, 1):
            try:
                response = requests.post(
                    self.generate_url,
                    json=payload,
                    headers={"Content-Type": "application/json"},
                    timeout=60
                )
                
                if response.status_code == 200:
                    try:
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            content = result["choices"][0]["message"]["content"]
                            return content
                    except json.JSONDecodeError:
                        response_text = response.text
                        if response_text.strip():
                            lines = response_text.strip().split('\n')
                            content_parts = []
                            for line in lines:
                                if line.startswith('data: '):
                                    try:
                                        data = json.loads(line[6:])
                                        if 'choices' in data and data['choices']:
                                            delta = data['choices'][0].get('delta', {})
                                            if 'content' in delta:
                                                content_parts.append(delta['content'])
                                    except:
                                        continue
                            if content_parts:
                                return ''.join(content_parts)
                        return "âœ… è¿æ¥æˆåŠŸï¼Œä½†å“åº”æ ¼å¼æœªçŸ¥"
                elif response.status_code == 500:
                    if i < len(configs):
                        continue
                    else:
                        return f"âŒ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ (500)"
                else:
                    return f"âŒ æœåŠ¡å™¨è¿”å›çŠ¶æ€ç  {response.status_code}"
            except Exception as e:
                if i < len(configs):
                    continue
                else:
                    return f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}"
        
        return "âŒ æ‰€æœ‰é…ç½®éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€ã€‚"
        """
        Query the RAG API with conversation history
        
        Args:
            messages: List of messages in API format
            temperature: Sampling temperature (0-1)
            top_p: Top-p sampling parameter (0.1-1)
            max_tokens: Maximum tokens to generate
            use_knowledge_base: Whether to use knowledge base
            
        Returns:
            The generated response
        """
        # ä½¿ç”¨ä¸å‰ç«¯ç›¸åŒçš„é…ç½®æ ¼å¼
        configs = [
            # é…ç½®1: å®Œæ•´å‚æ•° (ç±»ä¼¼å‰ç«¯)
            {
                "messages": messages,
                "collection_names": ["test"] if use_knowledge_base else [],
                "temperature": temperature,
                "top_p": top_p,
                "reranker_top_k": 10,
                "vdb_top_k": 10,
                "confidence_threshold": 0.5,
                "use_knowledge_base": use_knowledge_base,
                "enable_citations": True,
                "enable_guardrails": False
            },
            # é…ç½®2: ç®€åŒ–å‚æ•°
            {
                "messages": messages,
                "collection_names": [],
                "temperature": 0.1,
                "top_p": 0.9,
                "reranker_top_k": 10,
                "vdb_top_k": 10,
                "confidence_threshold": 0.5,
                "use_knowledge_base": False,
                "enable_citations": False,
                "enable_guardrails": False
            },
            # é…ç½®3: æœ€ç®€é…ç½®
            {
                "messages": messages,
                "use_knowledge_base": False,
                "temperature": 0.1,
                "max_tokens": min(max_tokens, 1000)
            }
        ]
        
        for i, payload in enumerate(configs, 1):
            try:
                response = requests.post(
                    self.generate_url,
                    json=payload,
                    headers={"Content-Type": "application/json"},
                    timeout=60
                )
                
                if response.status_code == 200:
                    try:
                        # å°è¯•è§£æ JSON å“åº”
                        result = response.json()
                        if "choices" in result and len(result["choices"]) > 0:
                            content = result["choices"][0]["message"]["content"]
                            if i > 1:
                                content = f"âš ï¸ ä½¿ç”¨ç®€åŒ–æ¨¡å¼å›ç­” (é…ç½®{i}):\n\n{content}"
                            return content
                    except json.JSONDecodeError:
                        # å¯èƒ½æ˜¯æµå¼å“åº”ï¼Œå°è¯•ç›´æ¥è¯»å–æ–‡æœ¬
                        response_text = response.text
                        if response_text.strip():
                            # ç®€å•å¤„ç†æµå¼å“åº”
                            lines = response_text.strip().split('\n')
                            content_parts = []
                            for line in lines:
                                if line.startswith('data: '):
                                    try:
                                        data = json.loads(line[6:])
                                        if 'choices' in data and data['choices']:
                                            delta = data['choices'][0].get('delta', {})
                                            if 'content' in delta:
                                                content_parts.append(delta['content'])
                                    except:
                                        continue
                            if content_parts:
                                content = ''.join(content_parts)
                                if i > 1:
                                    content = f"âš ï¸ ä½¿ç”¨ç®€åŒ–æ¨¡å¼å›ç­” (é…ç½®{i}):\n\n{content}"
                                return content
                        return f"âœ… è¿æ¥æˆåŠŸï¼Œä½†å“åº”æ ¼å¼æœªçŸ¥ (é…ç½®{i})"
                        
                elif response.status_code == 500:
                    if i < len(configs):
                        continue  # å°è¯•ä¸‹ä¸€ä¸ªé…ç½®
                    else:
                        return f"âŒ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ (500)ã€‚å¯èƒ½çš„åŸå› :\n" \
                               f"â€¢ æ¨¡å‹æœåŠ¡æœªå®Œå…¨å¯åŠ¨\n" \
                               f"â€¢ ç¼ºå°‘å¿…è¦çš„ä¾èµ–æœåŠ¡\n" \
                               f"â€¢ é…ç½®é—®é¢˜\n\n" \
                               f"è¯¦ç»†é”™è¯¯: {response.text[:200]}"
                else:
                    return f"âŒ æœåŠ¡å™¨è¿”å›çŠ¶æ€ç  {response.status_code}\n{response.text[:200]}"
                    
            except requests.exceptions.Timeout:
                if i < len(configs):
                    continue  # å°è¯•ä¸‹ä¸€ä¸ªé…ç½®
                else:
                    return "âŒ è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            except requests.exceptions.ConnectionError:
                return "âŒ æ— æ³•è¿æ¥åˆ°RAGæœåŠ¡å™¨ã€‚è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œã€‚"
            except Exception as e:
                if i < len(configs):
                    continue  # å°è¯•ä¸‹ä¸€ä¸ªé…ç½®
                else:
                    return f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}"
        
        return "âŒ æ‰€æœ‰é…ç½®éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€ã€‚"

def create_gradio_interface():
    """Create and configure the Gradio interface"""
    
    # Initialize the chatbot
    rag_bot = RAGChatBot()
    
    def chat_fn(message: str, history: List[List[str]], 
                temperature: float, top_p: float, max_tokens: int, 
                use_knowledge_base: bool, force_chinese: bool):
        """
        Handle chat interaction with streaming support
        
        Args:
            message: User input message
            history: Chat history
            temperature: Sampling temperature
            top_p: Top-p sampling
            max_tokens: Maximum tokens
            use_knowledge_base: Whether to use knowledge base
            force_chinese: Whether to force Chinese responses
            
        Yields:
            Updated history and empty string for message box
        """
        if not message.strip():
            yield history, ""
            return
        
        # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        history = history + [[message, ""]]
        yield history, ""
        
        # Check server health
        if not rag_bot.check_health():
            error_msg = "âŒ RAGæœåŠ¡å™¨æœªå“åº”ã€‚è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œåœ¨ http://192.168.81.253:8081"
            history[-1][1] = error_msg
            yield history, ""
            return
        
        # Convert to API format (ç³»ç»ŸæŒ‡ä»¤ä¼šåœ¨ format_messages_for_api ä¸­è‡ªåŠ¨æ·»åŠ )
        api_messages = rag_bot.format_messages_for_api(history[:-1], message)
        
        # å¦‚æœä¸å¼ºåˆ¶ä¸­æ–‡ï¼Œç§»é™¤ç³»ç»ŸæŒ‡ä»¤
        if not force_chinese and api_messages and api_messages[0]["role"] == "system":
            api_messages = api_messages[1:]
        
        # Get streaming response from RAG
        try:
            assistant_message = ""
            for chunk in rag_bot.query_rag_stream(
                messages=api_messages,
                temperature=temperature,
                top_p=top_p,
                max_tokens=max_tokens,
                use_knowledge_base=use_knowledge_base
            ):
                assistant_message += chunk
                # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯çš„å›å¤éƒ¨åˆ†
                history[-1][1] = assistant_message
                yield history, ""
                time.sleep(0.02)  # å°å»¶è¿Ÿä»¥å®ç°æ‰“å­—æ•ˆæœ
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            history[-1][1] = error_msg
            yield history, ""
    
    def clear_history():
        """Clear chat history"""
        return [], ""
    
    def check_server_status():
        """Check and return server status"""
        if rag_bot.check_health():
            return "âœ… RAGæœåŠ¡å™¨çŠ¶æ€: æ­£å¸¸"
        else:
            return "âŒ RAGæœåŠ¡å™¨çŠ¶æ€: æ— å“åº”"
    
    # Create the Gradio interface
    with gr.Blocks(
        title="NVIDIA RAG èŠå¤©æœºå™¨äºº",
        theme=gr.themes.Soft(),
        css="""
        /* å…¨å±€å­—ä½“è®¾ç½® */
        * {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
        }
        
        /* èŠå¤©å®¹å™¨ */
        .chat-container {
            max-height: 600px;
            overflow-y: auto;
        }
        
        /* æµå¼è¾“å‡ºåŠ¨ç”» */
        @keyframes typing {
            0% { opacity: 0.7; }
            50% { opacity: 1; }
            100% { opacity: 0.7; }
        }
        
        /* æ­£åœ¨è¾“å…¥æŒ‡ç¤ºå™¨ */
        .typing-indicator::after {
            content: 'â—';
            animation: typing 1.5s infinite;
            color: #22c55e;
            margin-left: 4px;
        }
        
        /* æ ‡é¢˜å­—ä½“ */
        h1, h2, h3, h4, h5, h6 {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 600;
        }
        
        /* è¾“å…¥æ¡†å­—ä½“ */
        .gr-textbox input, .gr-textbox textarea {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-size: 14px;
        }
        
        /* æŒ‰é’®å­—ä½“ */
        .gr-button {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 500;
        }
        
        /* èŠå¤©æ°”æ³¡å­—ä½“ */
        .message {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-size: 14px;
            line-height: 1.5;
        }
        
        /* æ ‡ç­¾å­—ä½“ */
        .gr-form label {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 500;
            font-size: 13px;
        }
        
        /* æ»‘å—æ ‡ç­¾ */
        .gr-slider label {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-size: 13px;
        }
        
        /* Markdown å†…å®¹ */
        .markdown {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
        }
        
        /* ä»£ç å­—ä½“ */
        code, pre {
            font-family: "SF Mono", Monaco, "Cascadia Code", "Roboto Mono", Consolas, "Courier New", monospace;
        }
        
        /* èŠå¤©æ°”æ³¡ä¼˜åŒ– */
        .chatbot .message-wrap {
            margin-bottom: 12px;
        }
        
        .chatbot .message {
            border-radius: 12px;
            padding: 12px 16px;
            margin: 4px 0;
        }
        """
    ) as demo:
        
        gr.Markdown(
            """
            # NVIDIA RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
            
            åŸºäº NVIDIA RAG Blueprint æ„å»ºçš„ä¼ä¸šçº§æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’ŒçŸ¥è¯†åº“æ£€ç´¢ã€‚
            
            **æ ¸å¿ƒåŠŸèƒ½:**
            â€¢ å¤šè½®å¯¹è¯å†å²è®°å¿†
            â€¢ åŸºäºå‘é‡æ•°æ®åº“çš„çŸ¥è¯†æ£€ç´¢
            â€¢ å¯è°ƒèŠ‚çš„ç”Ÿæˆå‚æ•°
            â€¢ å®æ—¶æœåŠ¡çŠ¶æ€ç›‘æ§
            """ + (f"\n\nğŸ”¥ **å¼€å‘æ¨¡å¼**: çƒ­é‡è½½å·²å¯ç”¨" if os.environ.get('GRADIO_RELOAD') == 'true' else ""),
            elem_classes=["markdown"]
        )
        
        with gr.Row():
            with gr.Column(scale=2):
                # Chat interface
                chatbot = gr.Chatbot(
                    label="å¯¹è¯å†å²",
                    height=500,
                    elem_classes=["chat-container"],
                    show_copy_button=True,
                    bubble_full_width=False,
                    sanitize_html=False,  # å…è®¸ HTML ä»¥æ”¯æŒæ›´å¥½çš„æ ¼å¼åŒ–
                    render_markdown=True   # æ”¯æŒ Markdown æ¸²æŸ“
                )
                
                with gr.Row():
                    msg_box = gr.Textbox(
                        label="è¾“å…¥æ‚¨çš„é—®é¢˜",
                        placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦è¯¢é—®çš„é—®é¢˜...",
                        scale=4,
                        show_label=False
                    )
                    send_btn = gr.Button("å‘é€", variant="primary", scale=1)
                
                with gr.Row():
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")
                    status_btn = gr.Button("æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€", variant="secondary")
                
                server_status = gr.Textbox(
                    label="æœåŠ¡å™¨çŠ¶æ€",
                    value="ç‚¹å‡»'æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€'æ¥æ£€æŸ¥è¿æ¥",
                    interactive=False
                )
            
            with gr.Column(scale=1):
                # Parameters panel
                gr.Markdown("### ç”Ÿæˆå‚æ•°", elem_classes=["markdown"])
                
                use_kb = gr.Checkbox(
                    label="å¯ç”¨çŸ¥è¯†åº“",
                    value=True,
                    info="åŸºäºå‘é‡æ•°æ®åº“å†…å®¹ç”Ÿæˆå›ç­”"
                )
                
                force_chinese = gr.Checkbox(
                    label="å¼ºåˆ¶ä¸­æ–‡å›ç­”",
                    value=True,
                    info="ç¡®ä¿æ‰€æœ‰å›ç­”éƒ½ä½¿ç”¨ä¸­æ–‡ï¼Œæ— è®ºé—®é¢˜ä½¿ç”¨ä»€ä¹ˆè¯­è¨€"
                )
                
                temperature = gr.Slider(
                    label="éšæœºæ€§ (Temperature)",
                    minimum=0.0,
                    maximum=1.0,
                    value=0.1,
                    step=0.1,
                    info="æ§åˆ¶å›ç­”çš„éšæœºæ€§ï¼Œå€¼è¶Šå°å›ç­”è¶Šç¡®å®š"
                )
                
                top_p = gr.Slider(
                    label="æ ¸é‡‡æ · (Top-p)",
                    minimum=0.1,
                    maximum=1.0,
                    value=0.9,
                    step=0.1,
                    info="æ§åˆ¶è¯æ±‡é€‰æ‹©çš„å¤šæ ·æ€§"
                )
                
                max_tokens = gr.Slider(
                    label="æœ€å¤§é•¿åº¦",
                    minimum=256,
                    maximum=8192,
                    value=4096,
                    step=256,
                    info="ç”Ÿæˆå›ç­”çš„æœ€å¤§å­—ç¬¦æ•°"
                )
                
                gr.Markdown(
                    """
                    ### ä½¿ç”¨è¯´æ˜
                    
                    **è¿æ¥è¦æ±‚**  
                    ç¡®ä¿ RAG æœåŠ¡è¿è¡Œåœ¨ `192.168.81.253:8081`
                    
                    **æ“ä½œæ­¥éª¤**  
                    1. åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­è¾“å…¥é—®é¢˜ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
                    2. ç‚¹å‡»å‘é€æˆ–æŒ‰å›è½¦é”®æäº¤
                    3. ç³»ç»Ÿå°†åŸºäºçŸ¥è¯†åº“ç”Ÿæˆå›ç­”
                    4. æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡è®°å¿†
                    
                    **è¯­è¨€è®¾ç½®**  
                    â€¢ **å¼ºåˆ¶ä¸­æ–‡å›ç­”**: å¯ç”¨åæ‰€æœ‰å›ç­”éƒ½ä½¿ç”¨ä¸­æ–‡
                    â€¢ æ— è®ºç”¨æˆ·ä½¿ç”¨ä¸­æ–‡æˆ–è‹±æ–‡æé—®ï¼ŒAI éƒ½ä¼šç”¨ä¸­æ–‡å›ç­”
                    â€¢ å…³é—­æ­¤é€‰é¡¹åï¼ŒAI ä¼šæ ¹æ®é—®é¢˜è¯­è¨€è‡ªåŠ¨é€‰æ‹©å›ç­”è¯­è¨€
                    
                    **å‚æ•°è°ƒèŠ‚**  
                    â€¢ **éšæœºæ€§**: æ§åˆ¶å›ç­”çš„åˆ›é€ æ€§
                    â€¢ **æ ¸é‡‡æ ·**: å½±å“ç”¨è¯é€‰æ‹©
                    â€¢ **æœ€å¤§é•¿åº¦**: é™åˆ¶å›ç­”é•¿åº¦
                    
                    **æ•…éšœæ’é™¤**  
                    å¦‚é‡è¿æ¥é—®é¢˜è¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
                    """,
                    elem_classes=["markdown"]
                )
        
        # Event handlers with streaming support
        send_btn.click(
            fn=chat_fn,
            inputs=[msg_box, chatbot, temperature, top_p, max_tokens, use_kb, force_chinese],
            outputs=[chatbot, msg_box],
            show_progress=False  # éšè—è¿›åº¦æ¡ä»¥è·å¾—æ›´å¥½çš„æµå¼ä½“éªŒ
        )
        
        msg_box.submit(
            fn=chat_fn,
            inputs=[msg_box, chatbot, temperature, top_p, max_tokens, use_kb, force_chinese],
            outputs=[chatbot, msg_box],
            show_progress=False  # éšè—è¿›åº¦æ¡ä»¥è·å¾—æ›´å¥½çš„æµå¼ä½“éªŒ
        )
        
        clear_btn.click(
            fn=clear_history,
            outputs=[chatbot, msg_box]
        )
        
        status_btn.click(
            fn=check_server_status,
            outputs=[server_status]
        )
        
        # Initialize server status on load
        demo.load(
            fn=check_server_status,
            outputs=[server_status]
        )
    
    return demo

def main():
    """Main function to launch the Gradio app"""
    
    # æ£€æŸ¥æ˜¯å¦åœ¨é‡è½½æ¨¡å¼
    is_reload_mode = os.environ.get('GRADIO_RELOAD', 'false').lower() == 'true'
    
    # Standalone execution
    print("å¯åŠ¨ NVIDIA RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ...")
    print("æœåŠ¡å™¨åœ°å€: http://192.168.81.253:8081")
    
    if is_reload_mode:
        print("ğŸ”¥ é‡è½½æ¨¡å¼å·²å¯ç”¨")
        print("æ­£åœ¨å¯åŠ¨ Web ç•Œé¢ï¼ˆæ”¯æŒçƒ­é‡è½½ï¼‰...")
    else:
        print("æ­£åœ¨å¯åŠ¨ Web ç•Œé¢...")
        
    demo = create_gradio_interface()
    
    launch_kwargs = {
        "server_name": "0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        "server_port": 7860,       # Gradioé»˜è®¤ç«¯å£
        "share": False,            # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
        "inbrowser": not is_reload_mode,  # é‡è½½æ¨¡å¼ä¸‹ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
        "quiet": is_reload_mode,   # é‡è½½æ¨¡å¼ä¸‹å‡å°‘è¾“å‡º
        "show_error": True         # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    }
    
    # åœ¨é‡è½½æ¨¡å¼ä¸‹å¯ç”¨é¢å¤–åŠŸèƒ½
    if is_reload_mode:
        launch_kwargs["debug"] = True
        
    demo.launch(**launch_kwargs)

if __name__ == "__main__":
    main()
